= Analytics
:description: Parallel data management for complex queries over many records, using a familiar {sqlpp} syntax.
:page-edition: Enterprise Edition:
:page-aliases: concept-docs:analytics-for-sdk-users.adoc


[abstract]
{description}


For complex and long-running queries, involving large ad hoc join, set, aggregation, and grouping operations, Couchbase Data Platform offers the xref:{version-server}@server:analytics:introduction.adoc[Couchbase Analytics Service (CBAS)].
This is the analytic counterpart to our xref:sqlpp-queries-with-sdk.adoc[operational data focussed Query Service].

The analytics service is available in xref:Capella]
or the Enterprise Edition of self-managed Couchbase Server.
A separate, as-a-service offering -- Capella Columnar -- is available as a https://info.couchbase.com/CapellaColumnar_Private_Preview_SignUp_LP.html[private preview].


== Getting Started

After familiarizing yourself with our xref:{version-server}@server:analytics:primer-beer.adoc[introductory primer],
in particular creating a dataset and linking it to a bucket to shadow the operational data,
try Couchbase Analytics using the Scala SDK.
Intentionally, the API for analytics is very similar to that of the query service.

Before starting, here's all imports used in the following examples:

[source,scala]
----
include::devguide:example$scala/Analytics.scala[tag=imports,indent=0]
----

Here's a complete example of doing an analytics query and handling the results:

[source,scala]
----
include::devguide:example$scala/Analytics.scala[tag=simple,indent=0]
----

Let's break this down.  First, we get the results in the form of a `Try[AnalyticsResult]`.
The Scala SDK returns `Try` rather than throwing exceptions, to allow you to handle errors in a functional way.
A `Try` can either be a `Success(AnalyticsResult)` if the query was successfully executed, or `Failure(Throwable)` if something went wrong.

An `AnalyticsResult` contains various things of interest, such as metrics, but the main thing we're interested in are the rows (results).  They're fetched with the `allRowsAs` call.
Note that the `flatMap` means the `allRowsAs` call will only be attempted if the initial query was successful.
Otherwise `rows` will contain the `Failure(Throwable)` from the query result.

Here we're fetching rows converted into `JsonObject`, but as with {sqlpp} (formerly N1QL) there's many more options available.
Rows can be returned as JSON representations from multiple third party Scala libraries, such as Circe, directly as case classes, and more.
Please see xref:howtos:json.adoc[JSON Libraries] for full details.

Finally, we pattern match on the `rows` to find whether the operations were successful.
We check explicitly for `AnalyticsError` which indicates an error from the analytics service.
There can be other errors returned, please see xref:howtos:error-handling.adoc[Error Handling] for details.

We can write that example more concisely, like this:

[source,scala]
----
include::devguide:example$scala/Analytics.scala[tag=simple-better,indent=0]
----

== Queries

A query can either be `simple` or be `parameterized`. If parameters are used, they can either be `positional` or `named`.
Here is one example of each:

[source,scala]
----
include::devguide:example$scala/Analytics.scala[tag=parameterised,indent=0]
----

[source,scala]
----
include::devguide:example$scala/Analytics.scala[tag=named,indent=0]
----

== Additional Parameters

The handful of additional parameters are illustrated here:

[source,scala]
----
include::devguide:example$scala/Analytics.scala[tag=parameters,indent=0]
----

=== Metadata
`AnalyticsResult` contains a `meta.metrics` field that contains useful metadata, such as `elapsedTime`, and `resultCount`:

[source,scala]
----
include::devguide:example$scala/Analytics.scala[tag=metrics,indent=0]
----

// For a full listing of available `Metrics` in `Metadata`, see the xref:concept-docs:analytics-for-sdk-users.adoc[Understanding Analytics] documentation.

== Streaming Large Result Sets
The Scala SDK provides three SDKs (documented further on xref:howtos:concurrent-async-apis.adoc[Choosing an API]):

* The blocking API you've seen so far, that returns an `AnalyticsResult` containing all rows.

* An async API that returns a `Future[AnalyticsResult]`, which also contains all rows.  This can be accessed like this:

[source,scala]
----
include::devguide:example$scala/Analytics.scala[tag=async,indent=0]
----

* A reactive API, that can be used to stream rows.

The former two APIs buffer all rows in-memory until they can be returned to you.  With smaller queries this is likely to be fine, but for large data sets this could lead to Java `OutOfMemoryError` exceptions.

The recommended solution is to use the reactive API.  Reactive programming is a sophisticated paradigm that is rapidly gaining popularity for its ability to handle, amongst other things, streaming large amounts of data over fallible networks, while allowing error handling and backpressure.

The Scala SDK exposes primitives from the https://projectreactor.io/[Project Reactor] library, most notably `Mono` and `Flux`.  We strongly recommend https://projectreactor.io/learn[learning] a little of this library first, and the following examples will assume basic familiarity with Reactor.

[NOTE]
You'll see both `reactor.core.scala.publisher` and `reactor.core.publisher` imports available for Reactor.  Use the former, it is the Scala-optimized variant that the Scala SDK will return.

Here's how to perform a query and stream the results using the reactive API:

[source,scala]
----
include::devguide:example$scala/Analytics.scala[tag=reactive,indent=0]
----

////
== Additional Resources

To learn more about using {sqlpp} for Analytics -- the first commercial implementation of SQL++ -- see our https://sqlplusplus-tutorial.couchbase.com/tutorial/#1[Tutorial Introduction to SQL++ for SQL users].

////
